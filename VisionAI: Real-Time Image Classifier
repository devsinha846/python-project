<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Image Classifier</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.0.4"></script>
    <style>
        #video {
            transform: scaleX(-1);
            display: none;
        }
        #canvas {
            transform: scaleX(-1);
        }
        .prediction-item {
            transition: all 0.3s ease;
        }
        .model-loading {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 0.6; }
            50% { opacity: 1; }
            100% { opacity: 0.6; }
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto py-8 px-4">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-indigo-700 mb-2">Real-Time Image Classifier</h1>
            <p class="text-lg text-gray-600">Using MobileNet model for on-device classification</p>
        </header>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-8">
            <div class="bg-white rounded-lg shadow-md p-6">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Camera Feed</h2>
                <div class="relative border-2 border-gray-300 rounded-lg overflow-hidden">
                    <video id="video" width="640" height="480" autoplay playsinline></video>
                    <canvas id="canvas" width="640" height="480" class="w-full bg-gray-200"></canvas>
                    <div class="absolute top-0 left-0 right-0 p-2 bg-black bg-opacity-50 text-white text-center">
                        Live Camera Classification
                    </div>
                </div>
                <div class="mt-4 flex justify-center space-x-4">
                    <button id="startBtn" class="bg-green-600 hover:bg-green-700 text-white px-4 py-2 rounded-md">
                        Start Camera
                    </button>
                    <button id="stopBtn" disabled class="bg-red-600 hover:bg-red-700 text-white px-4 py-2 rounded-md">
                        Stop Camera
                    </button>
                </div>
                <div class="mt-4">
                    <label class="block text-sm font-medium text-gray-700 mb-2">Model Confidence Threshold</label>
                    <input type="range" id="confidenceSlider" min="0" max="1" step="0.1" value="0.5" class="w-full">
                    <div class="flex justify-between text-xs text-gray-500">
                        <span>0%</span>
                        <span>50%</span>
                        <span>100%</span>
                    </div>
                </div>
                <div id="modelStatus" class="mt-4 p-3 bg-blue-100 text-blue-800 rounded-md text-center model-loading">
                    Loading model (234MB) - please wait...
                </div>
            </div>

            <div class="bg-white rounded-lg shadow-md p-6 h-full">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Classification Results</h2>
                <div id="predictionsContainer" class="space-y-2">
                    <div class="p-4 bg-gray-100 rounded-md text-center">
                        <p>Predictions will appear here when the model is loaded and camera is active</p>
                    </div>
                </div>
                <div class="mt-6">
                    <h3 class="text-lg font-medium text-gray-800 mb-2">Jupyter Notebook Instructions</h3>
                    <div class="bg-gray-50 p-4 rounded-md overflow-auto">
                        <pre class="text-xs text-gray-800">
# To run this in Jupyter Notebook:

1. Install required packages:
!pip install tensorflow opencv-python numpy matplotlib ipywidgets

2. Run this code cell for real-time classification:

import cv2
import numpy as np
import tensorflow as tf
from IPython.display import display, Image
import ipywidgets as widgets

# Load model
model = tf.keras.applications.MobileNetV2(weights='imagenet')

# Create widgets
button = widgets.Button(description="Start Camera")
output = widgets.Output()
confidence_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.05, description='Confidence:')
display(button, confidence_slider, output)

# Camera capture function
def classify_camera(b):
    camera = cv2.VideoCapture(0)
    try:
        while True:
            ret, frame = camera.read()
            if not ret:
                break
                
            # Preprocess frame
            resized_frame = cv2.resize(frame, (224, 224))
            expanded_frame = np.expand_dims(resized_frame, axis=0)
            preprocessed_frame = tf.keras.applications.mobilenet_v2.preprocess_input(expanded_frame)
            
            # Make prediction
            predictions = model.predict(preprocessed_frame)
            result = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]
            
            # Display results
            labels = [f"{label}: {round(prob*100, 2)}%" for (_, label, prob) in result 
                     if prob > confidence_slider.value]
            
            # Show image with predictions
            display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            for i, label in enumerate(labels):
                cv2.putText(display_frame, label, (10, 30 + i*30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
                
            with output:
                display(Image(data=cv2.imencode('.jpeg', display_frame)[1].tobytes()))
                output.clear_output(wait=True)
    except:
        camera.release()

button.on_click(classify_camera)
                        </pre>
                    </div>
                </div>
            </div>
        </div>

        <div class="bg-white rounded-lg shadow-md p-6 mt-8">
            <h2 class="text-2xl font-semibold text-gray-800 mb-4">Project Features</h2>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div class="p-4 border rounded-lg">
                    <div class="flex items-center mb-2">
                        <div class="w-10 h-10 bg-indigo-100 rounded-full flex items-center justify-center mr-3">
                            <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/720d95e9-a25b-45f2-9c43-3dd7aec1846c.png" alt="MobileNet model icon - abstract neural network representation" width="20" height="20" onerror="this.style.display='none'" />
                        </div>
                        <h3 class="font-semibold text-lg">MobileNetV2</h3>
                    </div>
                    <p class="text-gray-600">Uses pre-trained MobileNetV2 model (1.4M images, 1000 classes) for efficient real-time classification.</p>
                </div>
                <div class="p-4 border rounded-lg">
                    <div class="flex items-center mb-2">
                        <div class="w-10 h-10 bg-indigo-100 rounded-full flex items-center justify-center mr-3">
                            <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/f2321a48-2da3-412a-8e2c-62f25b7dc170.png" alt="Real-time processing icon - lightning bolt symbol" width="20" height="20" onerror="this.style.display='none'" />
                        </div>
                        <h3 class="font-semibold text-lg">Real-Time Processing</h3>
                    </div>
                    <p class="text-gray-600">Processes camera feed with 3-5 FPS in browser, faster in Jupyter (8-10 FPS with GPU).</p>
                </div>
                <div class="p-4 border rounded-lg">
                    <div class="flex items-center mb-2">
                        <div class="w-10 h-10 bg-indigo-100 rounded-full flex items-center justify-center mr-3">
                            <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/741d663b-e887-4a21-810d-0e447f038be6.png" alt="Jupyter notebook icon - code and data visualization symbols" width="20" height="20" onerror="this.style.display='none'" />
                        </div>
                        <h3 class="font-semibold text-lg">Jupyter Ready</h3>
                    </div>
                    <p class="text-gray-600">Includes complete code for Jupyter with interactive widgets for easy classroom demonstration.</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const predictionsContainer = document.getElementById('predictionsContainer');
        const confidenceSlider = document.getElementById('confidenceSlider');
        const modelStatus = document.getElementById('modelStatus');
        
        // Variables
        let model;
        let stream;
        let isPredicting = false;
        let lastPredictionTime = 0;
        const predictionInterval = 500; // Predict every 500ms
        
        // Load model
        async function loadModel() {
            try {
                model = await mobilenet.load({
                    version: 2,
                    alpha: 1.0,
                });
                modelStatus.textContent = "Model loaded successfully!";
                modelStatus.classList.remove('model-loading', 'bg-blue-100', 'text-blue-800');
                modelStatus.classList.add('bg-green-100', 'text-green-800');
                startBtn.disabled = false;
            } catch (error) {
                modelStatus.textContent = "Failed to load model: " + error.message;
                modelStatus.classList.remove('model-loading', 'bg-blue-100', 'text-blue-800');
                modelStatus.classList.add('bg-red-100', 'text-red-800');
            }
        }
        
        // Start camera
        async function startCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.play();
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
                
                // Start prediction loop
                isPredicting = true;
                predictLoop();
            } catch (error) {
                alert("Could not access camera: " + error.message);
            }
        }
        
        // Stop camera
        function stopCamera() {
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
            }
            
            isPredicting = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            
            // Clear canvas
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            predictionsContainer.innerHTML = `
                <div class="p-4 bg-gray-100 rounded-md text-center">
                    <p>Camera stopped. Press "Start Camera" to begin again.</p>
                </div>
            `;
        }
        
        // Main prediction loop
        async function predictLoop() {
            if (!isPredicting || !model) return;
            
            if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                requestAnimationFrame(predictLoop);
                return;
            }
            
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Throttle predictions
            const now = Date.now();
            if (now - lastPredictionTime < predictionInterval) {
                requestAnimationFrame(predictLoop);
                return;
            }
            lastPredictionTime = now;
            
            // Make prediction
            const predictions = await model.classify(canvas);
            displayPredictions(predictions);
            
            requestAnimationFrame(predictLoop);
        }
        
        // Display predictions
        function displayPredictions(predictions) {
            const confidenceThreshold = parseFloat(confidenceSlider.value);
            const filteredPredictions = predictions.filter(p => p.probability >= confidenceThreshold);
            
            if (filteredPredictions.length === 0) {
                predictionsContainer.innerHTML = `
                    <div class="p-4 bg-gray-100 rounded-md text-center">
                        <p>No predictions meet the current confidence threshold (${Math.round(confidenceThreshold * 100)}%)</p>
                    </div>
                `;
                return;
            }
            
            let predictionsHTML = '';
            filteredPredictions.forEach((pred, index) => {
                const widthPercentage = Math.round(pred.probability * 100);
                predictionsHTML += `
                    <div class="prediction-item p-3 bg-white border rounded-md">
                        <div class="flex justify-between mb-1">
                            <span class="font-medium text-gray-900">${pred.className}</span>
                            <span class="text-indigo-600">${Math.round(pred.probability * 100)}%</span>
                        </div>
                        <div class="w-full bg-gray-200 rounded-full h-2.5">
                            <div class="bg-indigo-600 h-2.5 rounded-full" style="width: ${widthPercentage}%"></div>
                        </div>
                    </div>
                `;
            });
            
            predictionsContainer.innerHTML = predictionsHTML;
        }
        
        // Event listeners
        startBtn.addEventListener('click', startCamera);
        stopBtn.addEventListener('click', stopCamera);
        confidenceSlider.addEventListener('input', () => {
            if (!isPredicting) {
                document.querySelector('#confidenceSlider + div span:nth-child(2)').textContent = 
                    `${Math.round(confidenceSlider.value * 100)}%`;
            }
        });
        
        // Initialize
        loadModel();
    </script>
</body>
</html>
